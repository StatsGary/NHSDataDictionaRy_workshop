<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>NHSDataDictionaRy Workshop</title>
    <meta charset="utf-8" />
    <meta name="author" content="Gary Hutson - Senior Data Scientist" />
    <meta name="date" content="2021-04-10" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/mango.css" type="text/css" />
    <link rel="stylesheet" href="css/mango-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# NHSDataDictionaRy Workshop
## NHS-R Community
### Gary Hutson - Senior Data Scientist
### 04/10/2021

---






background-image: url(man/figures/nhs-slide.png)
background-size: cover
font-color: red
class: center, bottom, inverse
## Welcome to the NHSDataDictionaRy package

---
## Introduction
Welcome to the NHSDataDictionaRy workshop. Today we will learn how to work with the data dictionary for NHS lookup tasks, as well as how to extend the package to work with any website. The concentration of the workshop will be broken down as such:

- Getting familiar with the NHSDataDictionaRy package and all the underlying functions
- Understanding the [nhs_data_elements()]() elements function and how to filter on this
- Gather text from any website and perform some text cleaning operations on the text, using a combination of functions contained in the package
- Using the [TableR](https://rdrr.io/cran/NHSDataDictionaRy/man/tableR.html) function to retrieve HTML tables from the data dictionary site and then extending this to other websites
- Working with XPath website elements with the NHSDataDictionaRy package
- How to use the package and retrieve website elements
- In general, a whistle stop tour of web scraping and how to do this with ease with the package

---
class: inverse, middle, left
# Loading libraries

---
# Loading libraries in NHSDataDictionaRy package

To load the libraries needed for this session you will need to bring in the following:


```r
library(NHSDataDictionaRy)
```

This will bring in the libraries needed to work with the package. The next step would be to check the dependencies in the package: 


```r
packrat:::recursivePackageDependencies("NHSDataDictionaRy", lib.loc = .libPaths())
```

```
##  [1] "R6"         "askpass"    "cli"        "crayon"     "curl"      
##  [6] "dplyr"      "ellipsis"   "fansi"      "generics"   "glue"      
## [11] "httr"       "jsonlite"   "lifecycle"  "magrittr"   "mime"      
## [16] "openssl"    "pillar"     "pkgconfig"  "purrr"      "rlang"     
## [21] "rvest"      "selectr"    "stringi"    "stringr"    "sys"       
## [26] "tibble"     "tidyselect" "utf8"       "vctrs"      "xml2"
```

---
class: inverse, middle, left
# Let's get scraping those data elements

---
## Starting with the nhs_data_elements() function

To retrieve the list of currrent NHS lookups in the table finder we use the underlying function:


```r
NHSDataDictionaRy::nhs_data_elements()
```

```
## # A tibble: 2,715 x 6
##    link_name     url       full_url    xpath_nat_code    xpath_default_cod~
##    &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;             &lt;chr&gt;             
##  1 ABBREVIATED ~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  2 ABDOMINAL X-~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  3 ABDOMINAL X-~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  4 ABDOMINAL X-~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  5 ABLATIVE THE~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  6 ABNORMALITY ~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  7 ACCESSIBLE I~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  8 ACCESSIBLE I~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
##  9 ACCESSIBLE I~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
## 10 ACCESSIBLE I~ data_ele~ https://da~ "//*[@id=\"eleme~ "//*[@id=\"elemen~
## # ... with 2,705 more rows, and 1 more variable: xpath_also_known &lt;chr&gt;
```
---
This function will then return the full list of data elements the package has scraped from the [NHS Data Dictionary website](https://www.datadictionary.nhs.uk/). 

An example of what has been scraped is on the next slide.

## Working with the scraped values

These scraped values will allow us to access the XPath elements of the website directly (don't worry if you don't know what an XPath is, we will get to that later on).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "google",
"highlightLines": true,
"seal": false,
"self_contained": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
