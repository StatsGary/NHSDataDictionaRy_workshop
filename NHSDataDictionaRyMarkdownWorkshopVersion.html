<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>NHSDataDictionaRy Workshop</title>
    <meta charset="utf-8" />
    <meta name="author" content="Gary Hutson - Senior Data Scientist" />
    <meta name="date" content="2021-04-10" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/mango.css" type="text/css" />
    <link rel="stylesheet" href="css/mango-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# NHSDataDictionaRy Workshop
## NHS-R Community
### Gary Hutson - Senior Data Scientist
### 04/10/2021

---





## Introduction

.pull-left[
Welcome to the NHSDataDictionaRy workshop. Today we will learn how to work with the data dictionary for NHS lookup tasks, as well as how to extend the package to work with any website. The concentration of the workshop will be broken down as such:

- Getting familiar with the NHSDataDictionaRy package and all the underlying functions
- Understanding the [nhs_data_elements()](https://rdrr.io/cran/NHSDataDictionaRy/man/nhs_data_elements.html) elements function and how to filter on this
- Gather text from any website and perform some text cleaning operations on the text, using a combination of functions contained in the package
- Using the [TableR](https://rdrr.io/cran/NHSDataDictionaRy/man/tableR.html) function to retrieve HTML tables from the data dictionary site and then extending this to other websites
- Working with XPath website elements with the [NHSDataDictionaRy package](https://cran.r-project.org/web/packages/NHSDataDictionaRy/vignettes/introduction.html)

]

.pull-right[
   &lt;a href="https://cran.r-project.org/web/packages/NHSDataDictionaRy/"&gt;&lt;img src = "man/figures/NHSDataDict.png"&gt;&lt;/a&gt;
]

---
## Watch our previous webinar on how to use this package
This was taken from a webinar we recorded a how to guide from the launch of the NHSDataDictionaRy package. This may be useful for referring to, but most of what is covered in the video will be in today's workshop. 
&lt;br&gt;&lt;/br&gt;


&lt;iframe width="600" height="400" src="https://www.youtube.com/embed/MqCFHCbTORs" align="left" title="NHSDataDictionaRy tutorial" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;


---
class: inverse, middle, left, hide-logo
# Loading libraries

---
# Loading libraries in NHSDataDictionaRy package

To load the libraries needed for this session you will need to bring in the following:


```r
library(NHSDataDictionaRy)
```

This will bring in the libraries needed to work with the package. The next step would be to check the dependencies in the package: 



---
class: inverse, middle, left, hide-logo
# Working with the TableR, nhs_data_elements and nhs_tableR functions

---
# Starting with the nhs_data_elements() function

To retrieve the list of currrent NHS lookups in the table finder we use the underlying function:



This function will then return the full list of data elements the package has scraped from the [NHS Data Dictionary website](https://www.datadictionary.nhs.uk/). 

An example of what has been scraped is on the next slide.

---

# Working with the scraped values

These scraped values will allow us to access the XPath elements of the website directly (don't worry if you don't know what an XPath is, we will get to that later on). To pull down a lookup table using the nhs_data_elements master reference we can use the TableR function to achieve this:

## Getting the Activity Treatment Function Codes



On the next slide you will see this has returned the lookup that I require:

---


This lookup will return the lookup table needed.
---
## What if the element is not returned?

I include an example of when an element is not returned, as not all elements from the list have corresponding HTML data tables to extract. A worked example is below:


This shows a ***NULL*** return, as there is no HTML present for the national code specified. This can be highlighted by using the NHS Data Dictionary website to highlight this.

---
## Checking the NHS Data Dictionary website

.pull-left[
&lt;img src="man/figures/NHSWebsiteDD1.png" alt="drawing" width="700" height="300"/&gt;
]

.pull-right[
You can see that the website contains no national code table, thus the message.

You will not be able to retrieve these elements from the site, so the package presents you with a warning that these HTML table tables do not exist. 

This is supposed to be informative and will allow you then to quickly inspect other items of interest.

]

---
background-image: url(man/figures/practice.jpg)
# Practice time - 10 minutes
Have a go at extracting elements from the nhs_data_elements() and TableR functions.

---
## Introducing a quicker way to retrieve elements

Until now we have been working long hand and finding with retrieving the list of lookups and then using the TableR function. There is a more simple function in the package to use to do this, but I wanted to get you familiar with using the returned elements such as the URL and XPath, because we will come on to this again later.

### nhs_table_findeR to the rescue



This function replaces the convoluted code we used earlier. 

---
## Using the lookup to join on to hospital data
We have this lookup and now we will generate some hospital data to match with our lookups:



---
## Using our custom data to join our lookups

Now we have some data to match, we can join our dynamic lookup from the web on to the lookup:




---
background-image: url(man/figures/practice.jpg)
# Practice time - 10 minutes
Try joining the main specialty code to this data

---
## Practice solution
This is pretty simple really - I just need to use the nhs_table_findeR function to get my lookup, if you are not sure what the string is to pass, use the nhs_data_elements() function to get all the strings. 




---
class: inverse, middle, left, hide-logo
# Wider use cases of the web scraping potential

---
## Scraping the Championship Football table
We could use the tableR function to scrape the results of the Championship table, here we will have to do some text processing as well to clean this up. I want to see how good or bad my team Nottingham Forest are doing.To get the Xpath I will need to use the Inspect button in google to copy this:

&lt;img src="man/figures/football_gif.gif" alt="drawing" height="350px" width="700px"/&gt;

---
## Using the retrieved Xpath from Google

The next step would be to copy the xpath and url into a variable, so we can differentiate them later.



Now let's get the HTML table from the website. Important to note that if it does not end in **/table** at the end of the url then it cannot be used with the TableR function, as it is not an HTML table object. 



---
## Let's clean the table up
The first stage would be to drop some of the less informative columns:





---
## Viewing the data on a scatter chart to explore key metrics


---
background-image: url(man/figures/practice.jpg)
# Practice time - 15 minutes
Have a go at retrieving some Xpath data from any website. Find a data table and bring it into R with the TableR function.

---
class: inverse, middle, left, hide-logo
# Scraping raw text from websites with xpathTextR function

---

## Extracting text from the NHS Data Dictionary website



---
## Cleaning the extracted text
The next stage is to clean the extracted text from the list element **result**:



Now you could use the inbuilt string functions in the package to strip the text further:



---
background-image: url(man/figures/practice.jpg)
# Practice time - 10 minutes
Have a go at finding a component from the NHS Data Dictionary, or other website, to test out this functionality.

---

# Capstone Project - Working through the whole solution

We will now utilise the tool to scrape the levels of COVID-19 by country, as I know it has been a hard year and we are getting there:

## Data Preparation



---

## Data Preparation (continued)

The data returns character strings, so I will use the first 4 columns from my selection above:



We then ***purrr::map_dfr*** over the data frame to convert to numeric and strip out the commas and then to fill in the NA values with a zero if they are missing. 


---
## Data Preparation (continued)

Finally, I will join the data back on to the original frame to bring back in the country:



Here we:

- Used cbind base R function to combine the reduced dataset and the numerical dataframe
- We renamed the Country field
- We then filtered out the blank countries and those where there is a total column

---
## The final dataset
This is the final dataset ready to be worked on with R:


  
With this dataset we will create some visuals. We could even store these in a data table with a time stamp over time to get the relevant days COVID-19 results.

---
## Visualising the results

We'll use our final data frame that we generated to create some visuals of the COVID rates, perhaps a scatter chart would be good for this purpose to see the ratio of total cases to total deaths.



On the next slide we will visualise the results:

---

## Visualising the results



---
class: inverse, middle, left, hide-logo
# Questions?






    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"seal": false,
"self_contained": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(../man/figures/NHSRComm.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 110px;
  height: 128px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    //':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
